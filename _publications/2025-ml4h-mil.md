---
title: "Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning"
collection: publications
category: conferences
permalink: /publication/2025-ml4h-mil
excerpt: 'We evaluate how well current MIL models capture inter-instance correlations by generating synthetic datasets and constructing a Bayes estimator as an optimal upper bound on model performance.'
date: 2025-01-01
venue: 'ML4H 2025 Symposium, Findings Track'
paperurl: 'https://arxiv.org/abs/2510.25759'
citation: 'Ethan Harvey, Dennis Johan Loevlie, and Michael C. Hughes. (2025). &quot;Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning.&quot; <i>ML4H 2025 Symposium, Findings Track</i>.'
---

This paper evaluates how well current multiple instance learning (MIL) models capture critical inter-instance correlations in medical imaging. By generating our own synthetic dataset, we construct a Bayes estimator that serves as an optimal upper bound on model performance. We benchmark both correlated MIL methods (such as attention-based and transformer architectures) and non-correlated approaches, revealing that there is a generalization gap in correlated and non-correlated MIL architectures and that narrowing that gap takes much more labeled data than is normally available in the medical domain.
